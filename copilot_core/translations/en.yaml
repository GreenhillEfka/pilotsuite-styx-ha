configuration:
  log_level:
    name: Log Level
    description: Set the logging verbosity (trace, debug, info, warning, error)
  auth_token:
    name: Auth Token
    description: Optional authentication token for API access. Leave empty to disable auth.
  conversation_ollama_url:
    name: Ollama URL
    description: URL of the Ollama server for local LLM inference
  conversation_ollama_model:
    name: Ollama Model
    description: Which Ollama model to use (e.g. qwen3:0.6b, qwen3:4b, llama3:8b)
  conversation_cloud_api_url:
    name: Cloud API URL (Fallback)
    description: Optional OpenAI-compatible endpoint URL for cloud fallback (e.g. https://api.openai.com/v1)
  conversation_cloud_api_key:
    name: Cloud API Key (Fallback)
    description: API key for the fallback cloud endpoint
  conversation_cloud_model:
    name: Cloud Model (Fallback)
    description: Model name to use on the fallback cloud endpoint (e.g. gpt-4o-mini)
  conversation_prefer_local:
    name: Prefer Local Ollama
    description: Try local Ollama first and use cloud fallback only when local is unavailable
  conversation_assistant_name:
    name: Assistant Name
    description: Name of the AI assistant shown in conversations
  conversation_enabled:
    name: Conversation Enabled
    description: Enable or disable the conversation/chat feature
